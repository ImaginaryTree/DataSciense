{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "mount_file_id": "1Yyl_36kLlsdLXzFkAaoSUWLDlysIn2DV",
      "authorship_tag": "ABX9TyNOxqyOIZvN+Rgg+ymxZAf2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ImaginaryTree/DataSciense/blob/main/PKM/CLSChecker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "INYtHRJFZ1NM"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import ExtraTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import RadiusNeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier    \n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.semi_supervised import LabelPropagation\n",
        "from sklearn.semi_supervised import LabelSpreading\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.naive_bayes import MultinomialNB  \n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.svm import NuSVC\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import pandas as pd\n",
        "classifiers = [\n",
        "    ExtraTreeClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    OneClassSVM(),\n",
        "    MLPClassifier(),\n",
        "    RadiusNeighborsClassifier(),\n",
        "    KNeighborsClassifier(),\n",
        "    SGDClassifier(),\n",
        "    RidgeClassifierCV(),\n",
        "    RidgeClassifier(),\n",
        "    PassiveAggressiveClassifier(),\n",
        "    GaussianProcessClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GradientBoostingClassifier(),\n",
        "    BaggingClassifier(),\n",
        "    ExtraTreesClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    BernoulliNB(),\n",
        "    CalibratedClassifierCV(),\n",
        "    GaussianNB(),\n",
        "    LabelPropagation(),\n",
        "    LabelSpreading(),\n",
        "    LinearDiscriminantAnalysis(),\n",
        "    LinearSVC(),\n",
        "    LogisticRegression(),\n",
        "    LogisticRegressionCV(),\n",
        "    MultinomialNB(),\n",
        "    NearestCentroid(),\n",
        "    NuSVC(),\n",
        "    Perceptron(),\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "    SVC(),\n",
        "    GaussianMixture()\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = pd.read_csv('https://raw.githubusercontent.com/ImaginaryTree/DataSciense/main/PKM/csv/train.csv')\n",
        "data_test = pd.read_csv('https://raw.githubusercontent.com/ImaginaryTree/DataSciense/main/PKM/csv/test.csv')\n",
        "\n",
        "X_train = data_train.drop(('class'), axis=1)\n",
        "y_train = data_train['class']\n",
        "display(X_train, y_train)\n",
        "\n",
        "X_test = data_test.drop('class', axis=1)\n",
        "y_test = data_test['class']\n",
        "\n",
        "display(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "A75XhL3xdwaL",
        "outputId": "72f3867e-070c-469e-8164-a6b12dc521f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        contrast    energy  homogeneity  correlation  dissimilarity       ASM  \\\n",
              "0     512.826000  0.014432     0.080614     0.690566      15.900818  0.000208   \n",
              "1     467.057694  0.014871     0.087467     0.715532      15.126038  0.000221   \n",
              "2     524.294265  0.014195     0.081258     0.699366      16.082849  0.000202   \n",
              "3     472.673600  0.014852     0.087986     0.714153      15.199941  0.000221   \n",
              "4     510.383251  0.014338     0.082743     0.703107      15.866788  0.000206   \n",
              "...          ...       ...          ...          ...            ...       ...   \n",
              "1065   45.361003  0.055359     0.416716     0.982504       3.214342  0.003065   \n",
              "1066   43.342724  0.057235     0.425658     0.983182       3.114166  0.003276   \n",
              "1067   44.150398  0.056865     0.425497     0.983134       3.129064  0.003234   \n",
              "1068   45.345021  0.058125     0.427900     0.982756       3.143370  0.003379   \n",
              "1069   40.521928  0.061267     0.442836     0.984319       2.967187  0.003754   \n",
              "\n",
              "      Entrophy  \n",
              "0     2.849807  \n",
              "1     2.800344  \n",
              "2     2.892728  \n",
              "3     2.810676  \n",
              "4     2.869656  \n",
              "...        ...  \n",
              "1065  1.719526  \n",
              "1066  1.693897  \n",
              "1067  1.704688  \n",
              "1068  1.718949  \n",
              "1069  1.662026  \n",
              "\n",
              "[1070 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e7813c2-a6bf-43ec-bdc8-34916b53bd53\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contrast</th>\n",
              "      <th>energy</th>\n",
              "      <th>homogeneity</th>\n",
              "      <th>correlation</th>\n",
              "      <th>dissimilarity</th>\n",
              "      <th>ASM</th>\n",
              "      <th>Entrophy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>512.826000</td>\n",
              "      <td>0.014432</td>\n",
              "      <td>0.080614</td>\n",
              "      <td>0.690566</td>\n",
              "      <td>15.900818</td>\n",
              "      <td>0.000208</td>\n",
              "      <td>2.849807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>467.057694</td>\n",
              "      <td>0.014871</td>\n",
              "      <td>0.087467</td>\n",
              "      <td>0.715532</td>\n",
              "      <td>15.126038</td>\n",
              "      <td>0.000221</td>\n",
              "      <td>2.800344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>524.294265</td>\n",
              "      <td>0.014195</td>\n",
              "      <td>0.081258</td>\n",
              "      <td>0.699366</td>\n",
              "      <td>16.082849</td>\n",
              "      <td>0.000202</td>\n",
              "      <td>2.892728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>472.673600</td>\n",
              "      <td>0.014852</td>\n",
              "      <td>0.087986</td>\n",
              "      <td>0.714153</td>\n",
              "      <td>15.199941</td>\n",
              "      <td>0.000221</td>\n",
              "      <td>2.810676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>510.383251</td>\n",
              "      <td>0.014338</td>\n",
              "      <td>0.082743</td>\n",
              "      <td>0.703107</td>\n",
              "      <td>15.866788</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>2.869656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1065</th>\n",
              "      <td>45.361003</td>\n",
              "      <td>0.055359</td>\n",
              "      <td>0.416716</td>\n",
              "      <td>0.982504</td>\n",
              "      <td>3.214342</td>\n",
              "      <td>0.003065</td>\n",
              "      <td>1.719526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1066</th>\n",
              "      <td>43.342724</td>\n",
              "      <td>0.057235</td>\n",
              "      <td>0.425658</td>\n",
              "      <td>0.983182</td>\n",
              "      <td>3.114166</td>\n",
              "      <td>0.003276</td>\n",
              "      <td>1.693897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1067</th>\n",
              "      <td>44.150398</td>\n",
              "      <td>0.056865</td>\n",
              "      <td>0.425497</td>\n",
              "      <td>0.983134</td>\n",
              "      <td>3.129064</td>\n",
              "      <td>0.003234</td>\n",
              "      <td>1.704688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1068</th>\n",
              "      <td>45.345021</td>\n",
              "      <td>0.058125</td>\n",
              "      <td>0.427900</td>\n",
              "      <td>0.982756</td>\n",
              "      <td>3.143370</td>\n",
              "      <td>0.003379</td>\n",
              "      <td>1.718949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1069</th>\n",
              "      <td>40.521928</td>\n",
              "      <td>0.061267</td>\n",
              "      <td>0.442836</td>\n",
              "      <td>0.984319</td>\n",
              "      <td>2.967187</td>\n",
              "      <td>0.003754</td>\n",
              "      <td>1.662026</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1070 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e7813c2-a6bf-43ec-bdc8-34916b53bd53')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e7813c2-a6bf-43ec-bdc8-34916b53bd53 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e7813c2-a6bf-43ec-bdc8-34916b53bd53');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0       0\n",
              "1       0\n",
              "2       0\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "1065    1\n",
              "1066    1\n",
              "1067    1\n",
              "1068    1\n",
              "1069    1\n",
              "Name: class, Length: 1070, dtype: int64"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      contrast    energy  homogeneity  correlation  dissimilarity       ASM  \\\n",
              "0    43.535638  0.053524     0.284826     0.803722       3.835220  0.002865   \n",
              "1    39.811623  0.057585     0.314434     0.818908       3.471286  0.003316   \n",
              "2    46.306606  0.053417     0.287220     0.801093       3.855550  0.002853   \n",
              "3    39.542779  0.058899     0.324780     0.821296       3.383995  0.003469   \n",
              "4    46.318942  0.055108     0.301536     0.802218       3.725326  0.003037   \n",
              "..         ...       ...          ...          ...            ...       ...   \n",
              "710  15.246847  0.053119     0.388336     0.997108       2.483774  0.002822   \n",
              "711  13.604039  0.054331     0.402915     0.997369       2.341824  0.002952   \n",
              "712  11.023583  0.059548     0.440744     0.997809       2.072355  0.003546   \n",
              "713  10.972931  0.059953     0.446306     0.997798       2.054957  0.003594   \n",
              "714  13.209086  0.056219     0.426025     0.997393       2.237305  0.003161   \n",
              "\n",
              "     Entrophy  \n",
              "0    1.038619  \n",
              "1    1.019195  \n",
              "2    1.071372  \n",
              "3    1.024997  \n",
              "4    1.067775  \n",
              "..        ...  \n",
              "710  1.230024  \n",
              "711  1.186865  \n",
              "712  1.091762  \n",
              "713  1.084536  \n",
              "714  1.148547  \n",
              "\n",
              "[715 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0623ac70-9f5b-42f3-9da7-92c4ff9a070e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contrast</th>\n",
              "      <th>energy</th>\n",
              "      <th>homogeneity</th>\n",
              "      <th>correlation</th>\n",
              "      <th>dissimilarity</th>\n",
              "      <th>ASM</th>\n",
              "      <th>Entrophy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>43.535638</td>\n",
              "      <td>0.053524</td>\n",
              "      <td>0.284826</td>\n",
              "      <td>0.803722</td>\n",
              "      <td>3.835220</td>\n",
              "      <td>0.002865</td>\n",
              "      <td>1.038619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>39.811623</td>\n",
              "      <td>0.057585</td>\n",
              "      <td>0.314434</td>\n",
              "      <td>0.818908</td>\n",
              "      <td>3.471286</td>\n",
              "      <td>0.003316</td>\n",
              "      <td>1.019195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>46.306606</td>\n",
              "      <td>0.053417</td>\n",
              "      <td>0.287220</td>\n",
              "      <td>0.801093</td>\n",
              "      <td>3.855550</td>\n",
              "      <td>0.002853</td>\n",
              "      <td>1.071372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>39.542779</td>\n",
              "      <td>0.058899</td>\n",
              "      <td>0.324780</td>\n",
              "      <td>0.821296</td>\n",
              "      <td>3.383995</td>\n",
              "      <td>0.003469</td>\n",
              "      <td>1.024997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>46.318942</td>\n",
              "      <td>0.055108</td>\n",
              "      <td>0.301536</td>\n",
              "      <td>0.802218</td>\n",
              "      <td>3.725326</td>\n",
              "      <td>0.003037</td>\n",
              "      <td>1.067775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>15.246847</td>\n",
              "      <td>0.053119</td>\n",
              "      <td>0.388336</td>\n",
              "      <td>0.997108</td>\n",
              "      <td>2.483774</td>\n",
              "      <td>0.002822</td>\n",
              "      <td>1.230024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711</th>\n",
              "      <td>13.604039</td>\n",
              "      <td>0.054331</td>\n",
              "      <td>0.402915</td>\n",
              "      <td>0.997369</td>\n",
              "      <td>2.341824</td>\n",
              "      <td>0.002952</td>\n",
              "      <td>1.186865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>712</th>\n",
              "      <td>11.023583</td>\n",
              "      <td>0.059548</td>\n",
              "      <td>0.440744</td>\n",
              "      <td>0.997809</td>\n",
              "      <td>2.072355</td>\n",
              "      <td>0.003546</td>\n",
              "      <td>1.091762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>713</th>\n",
              "      <td>10.972931</td>\n",
              "      <td>0.059953</td>\n",
              "      <td>0.446306</td>\n",
              "      <td>0.997798</td>\n",
              "      <td>2.054957</td>\n",
              "      <td>0.003594</td>\n",
              "      <td>1.084536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>13.209086</td>\n",
              "      <td>0.056219</td>\n",
              "      <td>0.426025</td>\n",
              "      <td>0.997393</td>\n",
              "      <td>2.237305</td>\n",
              "      <td>0.003161</td>\n",
              "      <td>1.148547</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>715 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0623ac70-9f5b-42f3-9da7-92c4ff9a070e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0623ac70-9f5b-42f3-9da7-92c4ff9a070e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0623ac70-9f5b-42f3-9da7-92c4ff9a070e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "710    1\n",
              "711    1\n",
              "712    1\n",
              "713    1\n",
              "714    1\n",
              "Name: class, Length: 715, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logging for Visual Comparison\n",
        "\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "import time\n",
        "\n",
        "log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\", \"Run Time\"]\n",
        "log = pd.DataFrame(columns=log_cols)\n",
        "\n",
        "for clf in classifiers:\n",
        "    run_time = 0\n",
        "    start = int(round(time.time() * 1000))\n",
        "\n",
        "    name = clf.__class__.__name__\n",
        "    print(\"=\"*30)\n",
        "    print(name)\n",
        "    \n",
        "    try:\n",
        "        clf.fit(X_train, y_train)\n",
        "        train_predictions = clf.predict(X_test)\n",
        "        acc = accuracy_score(y_test, train_predictions)\n",
        "        train_predictions = clf.predict_proba(X_test)\n",
        "        ll = log_loss(y_test, train_predictions)\n",
        "        run_time = (int(round(time.time() * 1000)) - start) / 1000\n",
        "        \n",
        "        print(\"Accuracy: {:.4%}\".format(acc))\n",
        "        print(\"Log Loss: {}\".format(ll))\n",
        "        \n",
        "        log_entry = pd.DataFrame([[name, acc*100, ll, run_time]], columns=log_cols)\n",
        "        log = log.append(log_entry)\n",
        "        \n",
        "    except:\n",
        "        print(\"Error occured.\")\n",
        "        \n",
        "    print(f\"Run time: {run_time} seconds.\")\n",
        "    \n",
        "print(\"=\"*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBTvCDSQeqO6",
        "outputId": "d5acbed9-1e94-4f5f-de3b-d29533b6b3df"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "ExtraTreeClassifier\n",
            "Accuracy: 64.1958%\n",
            "Log Loss: 12.366331128807182\n",
            "Run time: 0.007 seconds.\n",
            "==============================\n",
            "DecisionTreeClassifier\n",
            "Accuracy: 60.2797%\n",
            "Log Loss: 13.718898596020464\n",
            "Run time: 0.017 seconds.\n",
            "==============================\n",
            "OneClassSVM\n",
            "Error occured.\n",
            "Run time: 0 seconds.\n",
            "==============================\n",
            "MLPClassifier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 49.7902%\n",
            "Log Loss: 0.7658364162492844\n",
            "Run time: 1.167 seconds.\n",
            "==============================\n",
            "RadiusNeighborsClassifier\n",
            "Error occured.\n",
            "Run time: 0 seconds.\n",
            "==============================\n",
            "KNeighborsClassifier\n",
            "Accuracy: 53.7063%\n",
            "Log Loss: 1.106093223682906\n",
            "Run time: 0.045 seconds.\n",
            "==============================\n",
            "SGDClassifier\n",
            "Error occured.\n",
            "Run time: 0 seconds.\n",
            "==============================\n",
            "RidgeClassifierCV\n",
            "Error occured.\n",
            "Run time: 0 seconds.\n",
            "==============================\n",
            "RidgeClassifier\n",
            "Error occured.\n",
            "Run time: 0 seconds.\n",
            "==============================\n",
            "PassiveAggressiveClassifier\n",
            "Error occured.\n",
            "Run time: 0 seconds.\n",
            "==============================\n",
            "GaussianProcessClassifier\n",
            "Accuracy: 66.4336%\n",
            "Log Loss: 0.6266561637666606\n",
            "Run time: 1.461 seconds.\n",
            "==============================\n",
            "AdaBoostClassifier\n",
            "Accuracy: 40.0000%\n",
            "Log Loss: 0.7918119361391179\n",
            "Run time: 0.187 seconds.\n",
            "==============================\n",
            "GradientBoostingClassifier\n",
            "Accuracy: 53.4266%\n",
            "Log Loss: 1.4712197097005317\n",
            "Run time: 0.289 seconds.\n",
            "==============================\n",
            "BaggingClassifier\n",
            "Accuracy: 43.6364%\n",
            "Log Loss: 2.207910716544337\n",
            "Run time: 0.05 seconds.\n",
            "==============================\n",
            "ExtraTreesClassifier\n",
            "Accuracy: 45.7343%\n",
            "Log Loss: 0.9993424426557642\n",
            "Run time: 0.173 seconds.\n",
            "==============================\n",
            "RandomForestClassifier\n",
            "Accuracy: 45.5944%\n",
            "Log Loss: 0.8771238763686947\n",
            "Run time: 0.27 seconds.\n",
            "==============================\n",
            "BernoulliNB\n",
            "Accuracy: 78.6014%\n",
            "Log Loss: 0.5528027777368811\n",
            "Run time: 0.011 seconds.\n",
            "==============================\n",
            "CalibratedClassifierCV\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 30.0699%\n",
            "Log Loss: 0.9224205815315304\n",
            "Run time: 0.248 seconds.\n",
            "==============================\n",
            "GaussianNB\n",
            "Accuracy: 22.3776%\n",
            "Log Loss: 2.0472966014408644\n",
            "Run time: 0.011 seconds.\n",
            "==============================\n",
            "LabelPropagation\n",
            "Error occured.\n",
            "Run time: 0 seconds.\n",
            "==============================\n",
            "LabelSpreading\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
            "  probabilities /= normalizer\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
            "  probabilities /= normalizer\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
            "  probabilities /= normalizer\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
            "  probabilities /= normalizer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error occured.\n",
            "Run time: 0 seconds.\n",
            "==============================\n",
            "LinearDiscriminantAnalysis\n",
            "Accuracy: 35.1049%\n",
            "Log Loss: 2.4697953013254157\n",
            "Run time: 0.013 seconds.\n",
            "==============================\n",
            "LinearSVC\n",
            "Error occured.\n",
            "Run time: 0 seconds.\n",
            "==============================\n",
            "LogisticRegression\n",
            "Accuracy: 39.5804%\n",
            "Log Loss: 1.076097912966068\n",
            "Run time: 0.03 seconds.\n",
            "==============================\n",
            "LogisticRegressionCV\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 42.7972%\n",
            "Log Loss: 0.9710961135890752\n",
            "Run time: 0.958 seconds.\n",
            "==============================\n",
            "MultinomialNB\n",
            "Accuracy: 21.3986%\n",
            "Log Loss: 1.4964626365966294\n",
            "Run time: 0.01 seconds.\n",
            "==============================\n",
            "NearestCentroid\n",
            "Error occured.\n",
            "Run time: 0 seconds.\n",
            "==============================\n",
            "NuSVC\n",
            "Error occured.\n",
            "Run time: 0 seconds.\n",
            "==============================\n",
            "Perceptron\n",
            "Error occured.\n",
            "Run time: 0 seconds.\n",
            "==============================\n",
            "QuadraticDiscriminantAnalysis\n",
            "Accuracy: 55.1049%\n",
            "Log Loss: 10.998298025817382\n",
            "Run time: 0.009 seconds.\n",
            "==============================\n",
            "SVC\n",
            "Error occured.\n",
            "Run time: 0 seconds.\n",
            "==============================\n",
            "GaussianMixture\n",
            "Accuracy: 78.6014%\n",
            "Log Loss: 27.148589800972832\n",
            "Run time: 0.018 seconds.\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log = log.set_index('Classifier').sort_values('Accuracy', ascending=False)\n",
        "log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "s6bg3BlAf1AS",
        "outputId": "760823c9-bc48-4618-a891-295697fb1907"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                Accuracy   Log Loss  Run Time\n",
              "Classifier                                                   \n",
              "GaussianMixture                78.601399  27.148590     0.156\n",
              "BernoulliNB                    78.601399   0.552803     0.011\n",
              "GaussianProcessClassifier      66.433566   0.626656     1.414\n",
              "QuadraticDiscriminantAnalysis  55.104895  10.998298     0.008\n",
              "KNeighborsClassifier           53.706294   1.106093     0.043\n",
              "GradientBoostingClassifier     53.706294   1.429357     0.293\n",
              "MLPClassifier                  51.188811   0.746727     1.235\n",
              "ExtraTreesClassifier           47.832168   0.876745     0.172\n",
              "DecisionTreeClassifier         47.692308  18.066437     0.012\n",
              "BaggingClassifier              47.552448   2.142359     0.051\n",
              "ExtraTreeClassifier            46.853147  18.356273     0.009\n",
              "RandomForestClassifier         45.594406   0.808027     0.259\n",
              "LogisticRegressionCV           42.797203   0.971096     0.980\n",
              "AdaBoostClassifier             40.000000   0.791812     0.193\n",
              "LogisticRegression             39.580420   1.076098     0.032\n",
              "LinearDiscriminantAnalysis     35.104895   2.469795     0.025\n",
              "CalibratedClassifierCV         30.069930   0.922421     0.262\n",
              "GaussianNB                     22.377622   2.047297     0.010\n",
              "MultinomialNB                  21.398601   1.496463     0.010"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d79ec69-71f5-4401-bdae-530b434e3e9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Log Loss</th>\n",
              "      <th>Run Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>GaussianMixture</th>\n",
              "      <td>78.601399</td>\n",
              "      <td>27.148590</td>\n",
              "      <td>0.156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BernoulliNB</th>\n",
              "      <td>78.601399</td>\n",
              "      <td>0.552803</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GaussianProcessClassifier</th>\n",
              "      <td>66.433566</td>\n",
              "      <td>0.626656</td>\n",
              "      <td>1.414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QuadraticDiscriminantAnalysis</th>\n",
              "      <td>55.104895</td>\n",
              "      <td>10.998298</td>\n",
              "      <td>0.008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNeighborsClassifier</th>\n",
              "      <td>53.706294</td>\n",
              "      <td>1.106093</td>\n",
              "      <td>0.043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GradientBoostingClassifier</th>\n",
              "      <td>53.706294</td>\n",
              "      <td>1.429357</td>\n",
              "      <td>0.293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLPClassifier</th>\n",
              "      <td>51.188811</td>\n",
              "      <td>0.746727</td>\n",
              "      <td>1.235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreesClassifier</th>\n",
              "      <td>47.832168</td>\n",
              "      <td>0.876745</td>\n",
              "      <td>0.172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <td>47.692308</td>\n",
              "      <td>18.066437</td>\n",
              "      <td>0.012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BaggingClassifier</th>\n",
              "      <td>47.552448</td>\n",
              "      <td>2.142359</td>\n",
              "      <td>0.051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreeClassifier</th>\n",
              "      <td>46.853147</td>\n",
              "      <td>18.356273</td>\n",
              "      <td>0.009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>45.594406</td>\n",
              "      <td>0.808027</td>\n",
              "      <td>0.259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegressionCV</th>\n",
              "      <td>42.797203</td>\n",
              "      <td>0.971096</td>\n",
              "      <td>0.980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostClassifier</th>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.791812</td>\n",
              "      <td>0.193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>39.580420</td>\n",
              "      <td>1.076098</td>\n",
              "      <td>0.032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearDiscriminantAnalysis</th>\n",
              "      <td>35.104895</td>\n",
              "      <td>2.469795</td>\n",
              "      <td>0.025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CalibratedClassifierCV</th>\n",
              "      <td>30.069930</td>\n",
              "      <td>0.922421</td>\n",
              "      <td>0.262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GaussianNB</th>\n",
              "      <td>22.377622</td>\n",
              "      <td>2.047297</td>\n",
              "      <td>0.010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MultinomialNB</th>\n",
              "      <td>21.398601</td>\n",
              "      <td>1.496463</td>\n",
              "      <td>0.010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d79ec69-71f5-4401-bdae-530b434e3e9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d79ec69-71f5-4401-bdae-530b434e3e9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d79ec69-71f5-4401-bdae-530b434e3e9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Hyperparameter optimization "
      ],
      "metadata": {
        "id": "nJJ0OHtBgD7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "moS8SlKAggDS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = GradientBoostingClassifier()\n",
        "param_grid_1 = {\n",
        "    'loss' : ['deviance', 'exponential'],\n",
        "    'max_features' : ['sqrt', 'log2', 'None'],\n",
        "    'max_depth' : [2, 3, 4],\n",
        "    'learning_rate' : [0.1, 0.2],\n",
        "    'n_estimators' : [100, 200],\n",
        "    'min_samples_leaf' : [1, 2],\n",
        "    'min_samples_split' : [2, 3],\n",
        "}\n",
        "BernoulliNB_1 = GridSearchCV(estimator=model_1, param_grid=param_grid_1, scoring='roc_auc', cv=3, verbose=10)\n",
        "BernoulliNB_1.fit(X_train, y_train)\n",
        "\n",
        "y_pred_1 = gscv_1.predict(X_test)\n",
        "accuracy_1 = accuracy_score(y_test, y_pred_1)\n",
        "predict_proba_1 = BernoulliNB_1.predict_proba(X_test)\n",
        "log_loss_1 = log_loss(y_test, predict_proba_1)\n",
        "\n",
        "print(f\"Best Hyperparameters: {BernoulliNB_1.best_params_}, score: {BernoulliNB_1.best_score_}\")\n",
        "print(f\"Accuracy: {accuracy_1}, Log loss: {log_loss_1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "0riwVybtgjM6",
        "outputId": "d7fd0728-bb98-4635-aa45-c5319b8ca063"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
            "[CV 1/3; 1/288] START learning_rate=0.1, loss=deviance, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-28f4d53a1dec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     11\u001b[0m \u001b[0mBernoulliNB_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mBernoulliNB_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0my_pred_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgscv_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    246\u001b[0m                     \u001b[0;34m\"Invalid parameter %s for estimator %s. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                     \u001b[0;34m\"Check the list of available parameters \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m                     \u001b[0;34m\"with `estimator.get_params().keys()`.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m                 )\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid parameter learning_rate for estimator GaussianMixture(). Check the list of available parameters with `estimator.get_params().keys()`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = AdaBoostClassifier()\n",
        "param_grid_2 = {\n",
        "    'n_estimators' : [50, 100, 200]\n",
        "}\n",
        "BernoulliNB_2 = GridSearchCV(estimator=model_2, param_grid=param_grid_2, scoring='roc_auc', cv=5, verbose=10)\n",
        "BernoulliNB_2.fit(X_train, y_train)\n",
        "\n",
        "y_pred_2 = BernoulliNB_2.predict(X_test)\n",
        "accuracy_2 = accuracy_score(y_test, y_pred_2)\n",
        "predict_proba_2 = gscv_2.predict_proba(X_test)\n",
        "log_loss_2 = log_loss(y_test, predict_proba_2)\n",
        "\n",
        "print(f\"Best Hyperparameters: {gscv_2.best_params_}, score: {gscv_2.best_score_}\")\n",
        "print(f\"Accuracy: {accuracy_2}, Log loss: {log_loss_2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acajsYmKhrtx",
        "outputId": "d5fa5974-0107-4f26-d73c-f23fb3639c91"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
            "[CV 1/5; 1/3] START n_estimators=50.............................................\n",
            "[CV 1/5; 1/3] END ..............n_estimators=50;, score=0.758 total time=   0.1s\n",
            "[CV 2/5; 1/3] START n_estimators=50.............................................\n",
            "[CV 2/5; 1/3] END ..............n_estimators=50;, score=0.859 total time=   0.1s\n",
            "[CV 3/5; 1/3] START n_estimators=50.............................................\n",
            "[CV 3/5; 1/3] END ..............n_estimators=50;, score=0.993 total time=   0.1s\n",
            "[CV 4/5; 1/3] START n_estimators=50.............................................\n",
            "[CV 4/5; 1/3] END ..............n_estimators=50;, score=0.854 total time=   0.1s\n",
            "[CV 5/5; 1/3] START n_estimators=50.............................................\n",
            "[CV 5/5; 1/3] END ..............n_estimators=50;, score=0.373 total time=   0.1s\n",
            "[CV 1/5; 2/3] START n_estimators=100............................................\n",
            "[CV 1/5; 2/3] END .............n_estimators=100;, score=0.775 total time=   0.3s\n",
            "[CV 2/5; 2/3] START n_estimators=100............................................\n",
            "[CV 2/5; 2/3] END .............n_estimators=100;, score=0.950 total time=   0.3s\n",
            "[CV 3/5; 2/3] START n_estimators=100............................................\n",
            "[CV 3/5; 2/3] END .............n_estimators=100;, score=0.993 total time=   0.3s\n",
            "[CV 4/5; 2/3] START n_estimators=100............................................\n",
            "[CV 4/5; 2/3] END .............n_estimators=100;, score=0.838 total time=   0.2s\n",
            "[CV 5/5; 2/3] START n_estimators=100............................................\n",
            "[CV 5/5; 2/3] END .............n_estimators=100;, score=0.362 total time=   0.2s\n",
            "[CV 1/5; 3/3] START n_estimators=200............................................\n",
            "[CV 1/5; 3/3] END .............n_estimators=200;, score=0.758 total time=   0.5s\n",
            "[CV 2/5; 3/3] START n_estimators=200............................................\n",
            "[CV 2/5; 3/3] END .............n_estimators=200;, score=0.815 total time=   0.5s\n",
            "[CV 3/5; 3/3] START n_estimators=200............................................\n",
            "[CV 3/5; 3/3] END .............n_estimators=200;, score=0.996 total time=   0.5s\n",
            "[CV 4/5; 3/3] START n_estimators=200............................................\n",
            "[CV 4/5; 3/3] END .............n_estimators=200;, score=0.848 total time=   0.5s\n",
            "[CV 5/5; 3/3] START n_estimators=200............................................\n",
            "[CV 5/5; 3/3] END .............n_estimators=200;, score=0.372 total time=   0.5s\n",
            "Best Hyperparameters: {'n_estimators': 100}, score: 0.7837835286778949\n",
            "Accuracy: 0.413986013986014, Log loss: 0.7792421241466632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GridSearchCV.get_params(self).keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "dq-42S1DmBVt",
        "outputId": "728ffee6-a51b-40b2-a2db-a548e760a335"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-491d4faa16a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = MLPClassifier()\n",
        "param_grid_3 = {\n",
        "    'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
        "    'learning_rate' : ['constant', 'invscaling', 'adaptive'],\n",
        "    'solver' : ['lbfgs', 'sgd', 'adam']\n",
        "}\n",
        "gscv_3 = GridSearchCV(estimator=model_3, param_grid=param_grid_3, scoring='roc_auc', cv=3, verbose=10)\n",
        "gscv_3.fit(X_train, y_train)\n",
        "\n",
        "y_pred_3 = gscv_3.predict(X_test)\n",
        "accuracy_3 = accuracy_score(y_test, y_pred_3)\n",
        "predict_proba_3 = gscv_3.predict_proba(X_test)\n",
        "log_loss_3 = log_loss(y_test, predict_proba_3)\n",
        "\n",
        "print(f\"Best Hyperparameters: {gscv_3.best_params_}, score: {gscv_3.best_score_}\")\n",
        "print(f\"Accuracy: {accuracy_3}, Log loss: {log_loss_3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "VOWkxnC_h-H5",
        "outputId": "974b9d51-4e01-4beb-bae9-c4e83f0e8548"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
            "[CV 1/3; 1/36] START activation=identity, learning_rate=constant, solver=lbfgs..\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-42a059b5e63d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m }\n\u001b[1;32m      7\u001b[0m \u001b[0mgscv_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgscv_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0my_pred_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgscv_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    246\u001b[0m                     \u001b[0;34m\"Invalid parameter %s for estimator %s. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                     \u001b[0;34m\"Check the list of available parameters \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m                     \u001b[0;34m\"with `estimator.get_params().keys()`.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m                 )\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid parameter activation for estimator BernoulliNB(). Check the list of available parameters with `estimator.get_params().keys()`."
          ]
        }
      ]
    }
  ]
}